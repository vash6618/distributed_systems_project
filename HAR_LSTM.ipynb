{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR LSTM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vash6618/distributed_systems_project/blob/main/HAR_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNIyDx2_XDbS"
      },
      "source": [
        "from pandas import read_csv\n",
        "from numpy import dstack\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ4imFnn_yZz"
      },
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoMpz3CKCJPb"
      },
      "source": [
        "\n",
        "# load a list of files into a 3D array of [samples, timesteps, features]\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhuJGC6cCNuO"
      },
      "source": [
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LccdYBN9CTgU"
      },
      "source": [
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'UCI HAR Dataset/')\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + 'UCI HAR Dataset/')\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ6aNVd3ngrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84eebb36-c9e5-45a7-b3f5-022e171fa854"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlJozwK3WAJA",
        "outputId": "824d37e9-a8a1-4c5a-b402-e62f7317ae1d"
      },
      "source": [
        "trainX, trainy, testX, testy = load_dataset('/content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/Research project/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgcVPG-LbM0n"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
        "from tensorflow.keras.layers import ConvLSTM2D \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deLJe2Hqhjie"
      },
      "source": [
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "  print(scores)\n",
        "  m, s = np.nanmean(scores), np.nanstd(scores)\n",
        "  print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YuMChY2UogN"
      },
      "source": [
        "def evaluate_conv_lstm_model(trainX, trainy, testX, testy):\n",
        "\t# define model\n",
        "\tverbose, epochs, batch_size = 0, 25, 64\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "\tn_steps, n_length = 4, 32\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\ttestX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu'))\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit network\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "\treturn accuracy, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOE64w_JTtP-"
      },
      "source": [
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "    verbose, epochs, batch_size = 0, 15, 64\n",
        "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # fit network\n",
        "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "    return accuracy, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ZGdvFYUp4e"
      },
      "source": [
        "def run_experiment_with_conv_lstm(repeats=1):\n",
        "  # trainX, trainy, testX, testy = load_dataset()\n",
        "  scores = list()\n",
        "  models = list()\n",
        "  for r in range(repeats):\n",
        "    score, model = evaluate_conv_lstm_model(trainX, trainy, testX, testy)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "    models.append(model)\n",
        "  summarize_results(scores)\n",
        "  return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl7iQie2T2OB"
      },
      "source": [
        "def run_experiment_with_lstm(repeats=1):\n",
        "  # trainX, trainy, testX, testy = load_dataset()\n",
        "  scores = list()\n",
        "  models = list()\n",
        "  for r in range(repeats):\n",
        "    score, model = evaluate_model(trainX, trainy, testX, testy)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "    models.append(model)\n",
        "  summarize_results(scores)\n",
        "  return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjrMk9u6T7i3",
        "outputId": "03ceee72-2d9a-42c4-e7e2-d574ce1aee20"
      },
      "source": [
        "models = run_experiment_with_lstm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">#1: 90.499\n",
            "[90.49881100654602]\n",
            "Accuracy: 90.499% (+/-0.000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iyzl3uy_Zy0D"
      },
      "source": [
        "models = run_experiment_with_conv_lstm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON9Eex1paUpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b54e45-de6c-475b-d84a-adf73eda8ac9"
      },
      "source": [
        "print(models)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fbcf3579d50>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZThzQtea4DsP",
        "outputId": "1f494c13-40dc-4f4a-d267-a4a23e4f4b51"
      },
      "source": [
        "for model in models:\n",
        "  print(model.layers[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x7fbcf3cc1190>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHz7GlKUl5KO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30fbffae-b1e9-42c4-ce9e-d2b4d42c363d"
      },
      "source": [
        "models[0].save('/content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_normal_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_normal_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_normal_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ZVxeaHVs6X"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_normal_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-wKDr-lWQNH",
        "outputId": "065e2fa6-7ebb-410a-dd1b-411c4288ab82"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fbcec62e4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzvMtYDH_WKL",
        "outputId": "e20a0b9c-ba89-4779-911e-042a3cbea5dc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100)               44000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 606       \n",
            "=================================================================\n",
            "Total params: 54,706\n",
            "Trainable params: 54,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_DV5LXKXFKo"
      },
      "source": [
        "def print_model_sparsity(pruned_model):\n",
        "  \"\"\"Prints sparsity for the pruned layers in the model.\n",
        "  Model Sparsity Summary\n",
        "  --\n",
        "  prune_lstm_1: (kernel, 0.5), (recurrent_kernel, 0.6)\n",
        "  prune_dense_1: (kernel, 0.5)\n",
        "  Args:\n",
        "    pruned_model: keras model to summarize.\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  def _get_sparsity(weights):\n",
        "    return 1.0 - np.count_nonzero(weights) / float(weights.size)\n",
        "\n",
        "  print(\"Model Sparsity Summary ({})\".format(pruned_model.name))\n",
        "  print(\"--\")\n",
        "  for layer in pruned_model.layers:\n",
        "    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n",
        "      prunable_weights = layer.layer.get_prunable_weights()\n",
        "      if prunable_weights:\n",
        "        print(\"start prunable ----------------------------\")\n",
        "        print(\"{}: {}\".format(\n",
        "            layer.name, \", \".join([\n",
        "                \"({}, {})\".format(weight.name,\n",
        "                                  str(_get_sparsity(K.get_value(weight))))\n",
        "                for weight in prunable_weights\n",
        "            ])))\n",
        "        print(\"stop prunable ----------------------------\")\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLrm5_KFR7Mw",
        "outputId": "4f6516a4-c189-4644-f524-0b1b3bccd122"
      },
      "source": [
        "!pip install tensorflow_model_optimization\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.preprocessing.sequence as sequence\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
        "\n",
        "compressed_pruned_model = prune.prune_low_magnitude(model, pruning_schedule.PolynomialDecay(\n",
        "    initial_sparsity=0.3, final_sparsity=0.7, begin_step=1000, end_step=3000))\n",
        "\n",
        "print(compressed_pruned_model.summary())\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "compressed_pruned_model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "# print_model_sparsity(pruned_model)\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "# print(\"Train...\")\n",
        "# pruned_model.fit(trainX, trainy, batch_size=batch_size, epochs=2,\n",
        "#           callbacks=[pruning_callbacks.UpdatePruningStep()], validation_split=0.1)\n",
        "score, acc = compressed_pruned_model.evaluate(testX, testy,\n",
        "                            batch_size=batch_size)\n",
        "# print_model_sparsity(pruned_model)\n",
        "print(\"Test score:\", score)\n",
        "print(\"Test accuracy:\", acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\r\u001b[K     |██                              | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 20.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 16.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 14.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_lstm (Pr (None, 100)               87603     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dropout  (None, 100)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 100)               20102     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_1  (None, 6)                 1208      \n",
            "=================================================================\n",
            "Total params: 108,914\n",
            "Trainable params: 54,706\n",
            "Non-trainable params: 54,208\n",
            "_________________________________________________________________\n",
            "None\n",
            "47/47 [==============================] - 3s 42ms/step - loss: 0.3706 - accuracy: 0.8626\n",
            "Test score: 0.31666630506515503\n",
            "Test accuracy: 0.9049881100654602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iYHMr_KffJP"
      },
      "source": [
        "# from tensorflow import keras\n",
        "\n",
        "# compressed_pruned_model.save('/content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_pruned_model')\n",
        "\n",
        "# pruned_model_lstm = keras.models.load_model('/content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/LSTM_pruned_model')\n",
        "# pruned_model_lstm.compile(loss=\"categorical_crossentropy\",\n",
        "#               optimizer=\"adam\",\n",
        "#               metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9685Q8_ANAGJ",
        "outputId": "68569357-7ecb-4eb5-e067-6d1011a23f0c"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "export_pruned_LSTM = tfmot.sparsity.keras.strip_pruning(compressed_pruned_model)\n",
        "export_pruned_LSTM.save('/content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_pruned_exported')\n",
        "\n",
        "# _, pruned_lstm_file = tempfile.mkstemp('tfpruned.h5')\n",
        "# tf.keras.models.save_model(model_for_export, pruned_lstm_file, include_optimizer=False)\n",
        "# print('Saved pruned Keras model to:', pruned_lstm_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_pruned_exported/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/all_models/LSTM_pruned_exported/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJTnIP8zoYbD",
        "outputId": "b99732f4-d727-488d-9e78-84cae93e7948"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "\n",
        "export_pruned_LSTM.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "# print(\"Train...\")\n",
        "# pruned_model.fit(trainX, trainy, batch_size=batch_size, epochs=2,\n",
        "#           callbacks=[pruning_callbacks.UpdatePruningStep()], validation_split=0.1)\n",
        "score, acc = export_pruned_LSTM.evaluate(testX, testy,\n",
        "                            batch_size=batch_size)\n",
        "# print_model_sparsity(pruned_model)\n",
        "print(\"Test score:\", score)\n",
        "print(\"Test accuracy:\", acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 3s 41ms/step - loss: 0.3706 - accuracy: 0.8626\n",
            "Test score: 0.31666630506515503\n",
            "Test accuracy: 0.9049881100654602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1otfU5EkZyp",
        "outputId": "4673655b-3107-4ec5-8a21-445d7a163aa3"
      },
      "source": [
        "import tempfile\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(export_pruned_LSTM)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('_quantized.tflite')\n",
        "\n",
        "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_and_pruned_tflite_model)\n",
        "\n",
        "print('Saved quantized and pruned TFLite model to:', quantized_and_pruned_tflite_file)\n",
        "\n",
        "# print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "# print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_pruned_tflite_file)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvn4z7z1g/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvn4z7z1g/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved quantized and pruned TFLite model to: /tmp/tmpdc58dx0y_quantized.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5DQzhp3NapQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca86ce30-a3f3-431c-cdc8-5257e6f33e27"
      },
      "source": [
        "tflite_interpreter = tf.lite.Interpreter(model_path=quantized_and_pruned_tflite_file)\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== Input details ==\n",
            "name: serving_default_lstm_input:0\n",
            "shape: [  1 128   9]\n",
            "type: <class 'numpy.float32'>\n",
            "\n",
            "== Output details ==\n",
            "name: StatefulPartitionedCall:0\n",
            "shape: [1 6]\n",
            "type: <class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EszhmW1N7R6",
        "outputId": "0ef7b332-40c1-4955-d631-75b635446a48"
      },
      "source": [
        "tflite_interpreter.resize_tensor_input(input_details[0]['index'], (1, 128, 9))\n",
        "tflite_interpreter.resize_tensor_input(output_details[0]['index'], (1, 6))\n",
        "tflite_interpreter.allocate_tensors()\n",
        "\n",
        "input_details = tflite_interpreter.get_input_details()\n",
        "output_details = tflite_interpreter.get_output_details()\n",
        "\n",
        "print(\"== Input details ==\")\n",
        "print(\"name:\", input_details[0]['name'])\n",
        "print(\"shape:\", input_details[0]['shape'])\n",
        "print(\"type:\", input_details[0]['dtype'])\n",
        "print(\"index:\", input_details[0]['index'])\n",
        "\n",
        "print(\"\\n== Output details ==\")\n",
        "print(\"name:\", output_details[0]['name'])\n",
        "print(\"shape:\", output_details[0]['shape'])\n",
        "print(\"type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== Input details ==\n",
            "name: serving_default_lstm_input:0\n",
            "shape: [  1 128   9]\n",
            "type: <class 'numpy.float32'>\n",
            "index: 0\n",
            "\n",
            "== Output details ==\n",
            "name: StatefulPartitionedCall:0\n",
            "shape: [1 6]\n",
            "type: <class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRb0OIM-v0c2",
        "outputId": "55dff5e0-0da4-49e0-f5ec-d2b7cbde46ad"
      },
      "source": [
        "\n",
        "x_test = tf.dtypes.cast(testX,tf.float32)\n",
        "# x_test = x_test.numpy()\n",
        "x_test[0:64, :, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 128, 9), dtype=float32, numpy=\n",
              "array([[[ 1.041216e+00, -2.697959e-01,  2.377977e-02, ...,\n",
              "          4.374637e-01,  5.313492e-01,  1.365279e-01],\n",
              "        [ 1.041803e+00, -2.800250e-01,  7.629271e-02, ...,\n",
              "          4.682641e-01,  7.210685e-01,  9.762239e-02],\n",
              "        [ 1.039086e+00, -2.926631e-01,  1.474754e-01, ...,\n",
              "          4.982574e-01,  5.203284e-01,  8.355578e-02],\n",
              "        ...,\n",
              "        [ 9.930164e-01, -2.599865e-01,  1.443951e-01, ...,\n",
              "         -5.055856e-03, -7.734212e-02,  3.225787e-02],\n",
              "        [ 9.932414e-01, -2.620643e-01,  1.447033e-01, ...,\n",
              "         -2.043194e-02, -7.297300e-02,  2.700848e-02],\n",
              "        [ 9.943906e-01, -2.641348e-01,  1.454939e-01, ...,\n",
              "         -2.999741e-02, -7.064875e-02,  3.054609e-02]],\n",
              "\n",
              "       [[ 9.991921e-01, -2.649349e-01,  1.256164e-01, ...,\n",
              "          1.702878e-01, -6.137388e-02,  5.509624e-02],\n",
              "        [ 9.946787e-01, -2.532142e-01,  1.256249e-01, ...,\n",
              "          1.752221e-01, -9.536355e-02,  4.334361e-02],\n",
              "        [ 9.935518e-01, -2.565887e-01,  1.163814e-01, ...,\n",
              "          1.308618e-01, -1.464495e-01,  5.239831e-02],\n",
              "        ...,\n",
              "        [ 1.001861e+00, -2.619359e-01,  1.527878e-01, ...,\n",
              "         -1.746929e-02, -4.128761e-02,  5.831106e-02],\n",
              "        [ 9.975208e-01, -2.713225e-01,  1.398428e-01, ...,\n",
              "         -2.124615e-02, -3.632182e-02,  5.100018e-02],\n",
              "        [ 9.928615e-01, -2.799715e-01,  1.213135e-01, ...,\n",
              "         -2.108687e-02, -1.963055e-02,  3.697936e-02]],\n",
              "\n",
              "       [[ 9.975931e-01, -2.639912e-01,  1.507741e-01, ...,\n",
              "         -3.872650e-02, -6.024968e-02,  2.928903e-02],\n",
              "        [ 9.989703e-01, -2.638194e-01,  1.539427e-01, ...,\n",
              "         -4.728239e-02, -5.175620e-02,  2.536597e-02],\n",
              "        [ 9.970574e-01, -2.638495e-01,  1.441536e-01, ...,\n",
              "         -5.390624e-02, -5.042757e-02,  2.482575e-02],\n",
              "        ...,\n",
              "        [ 9.918802e-01, -2.836712e-01,  1.326780e-01, ...,\n",
              "         -3.089945e-02, -3.714901e-02,  2.032818e-02],\n",
              "        [ 9.906626e-01, -2.805970e-01,  1.326941e-01, ...,\n",
              "         -3.537277e-02, -3.409071e-02,  1.645414e-02],\n",
              "        [ 9.882446e-01, -2.822329e-01,  1.321175e-01, ...,\n",
              "         -3.536986e-02, -3.040650e-02,  1.416688e-02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.719908e-01,  7.270977e-01,  6.756066e-01, ...,\n",
              "          1.098802e-03,  5.527446e-03, -2.798081e-03],\n",
              "        [-1.674146e-01,  7.276918e-01,  6.746968e-01, ...,\n",
              "         -1.878751e-03,  6.820680e-03, -3.285819e-03],\n",
              "        [-1.693270e-01,  7.264030e-01,  6.818224e-01, ...,\n",
              "          1.145507e-03,  5.211701e-03, -5.420706e-03],\n",
              "        ...,\n",
              "        [-1.688622e-01,  7.246349e-01,  6.749930e-01, ...,\n",
              "          1.007988e-02,  2.869146e-03,  2.578357e-03],\n",
              "        [-1.710986e-01,  7.235022e-01,  6.783716e-01, ...,\n",
              "          7.607691e-03, -3.398103e-03,  1.086563e-02],\n",
              "        [-1.657256e-01,  7.229348e-01,  6.802797e-01, ...,\n",
              "          4.366490e-03, -1.006091e-02,  1.456597e-02]],\n",
              "\n",
              "       [[-1.751748e-01,  7.249285e-01,  6.787371e-01, ...,\n",
              "         -2.220373e-03,  4.760469e-03, -1.461112e-03],\n",
              "        [-1.720677e-01,  7.270217e-01,  6.733702e-01, ...,\n",
              "         -2.381900e-03,  3.473898e-03,  3.331408e-04],\n",
              "        [-1.699367e-01,  7.264660e-01,  6.737018e-01, ...,\n",
              "          1.754401e-03,  3.477930e-03,  2.928406e-03],\n",
              "        ...,\n",
              "        [-1.607784e-01,  7.331923e-01,  6.697692e-01, ...,\n",
              "          3.365921e-03,  2.045945e-03,  5.134929e-03],\n",
              "        [-1.609051e-01,  7.321547e-01,  6.713469e-01, ...,\n",
              "          4.226235e-03, -1.101769e-05,  6.662251e-03],\n",
              "        [-1.614097e-01,  7.299968e-01,  6.760936e-01, ...,\n",
              "          4.951734e-03, -3.195972e-03,  5.169021e-03]],\n",
              "\n",
              "       [[-1.602512e-01,  7.243674e-01,  6.801951e-01, ...,\n",
              "          5.944612e-03, -6.255626e-03,  1.046351e-02],\n",
              "        [-1.644128e-01,  7.229109e-01,  6.761239e-01, ...,\n",
              "          4.832071e-03, -3.266312e-03,  5.790235e-03],\n",
              "        [-1.669040e-01,  7.216650e-01,  6.739346e-01, ...,\n",
              "          1.689505e-03, -3.838486e-03,  7.548117e-03],\n",
              "        ...,\n",
              "        [-1.691387e-01,  7.262967e-01,  6.735072e-01, ...,\n",
              "         -5.289665e-03, -5.840696e-04, -9.520890e-03],\n",
              "        [-1.684653e-01,  7.265730e-01,  6.708120e-01, ...,\n",
              "         -7.492337e-03, -4.941369e-04, -1.191385e-02],\n",
              "        [-1.701334e-01,  7.263861e-01,  6.697495e-01, ...,\n",
              "         -4.840927e-03, -7.231203e-05, -1.063317e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIr1YGO-lyQk",
        "outputId": "1a1b8048-cffb-4298-bb25-595521e6b5e8"
      },
      "source": [
        "output_list = []\n",
        "for i in range(2947):\n",
        "  tflite_interpreter.set_tensor(input_details[0]['index'], x_test[i:i+1, :, :])\n",
        "\n",
        "  tflite_interpreter.invoke()\n",
        "\n",
        "  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
        "  output_list += tflite_model_predictions.tolist()\n",
        "# print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "# print(\"Actual output :- \", tflite_model_predictions)\n",
        "print(len(output_list))\n",
        "print(output_list[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2947\n",
            "[[0.00025476032169535756, 4.884186637355015e-05, 0.0002797898487187922, 0.05096079036593437, 0.948441207408905, 1.455172423447948e-05], [0.00014442350948229432, 2.3915972633403726e-05, 0.00015379564138129354, 0.039592936635017395, 0.960078239440918, 6.6443808464100584e-06], [0.0001280668657273054, 2.0475148630794138e-05, 0.00013545829278882593, 0.03586583957076073, 0.963844895362854, 5.31522437086096e-06], [0.00010479502816451713, 1.658186738495715e-05, 0.00010883259528782219, 0.03468989580869675, 0.9650756120681763, 4.305918992031366e-06], [0.00010183606354985386, 1.662605609453749e-05, 0.00010567524441285059, 0.03524995595216751, 0.9645214676856995, 4.534772415354382e-06], [0.00010667312744772062, 1.7345226297038607e-05, 0.00011127660400234163, 0.034875087440013885, 0.9648849964141846, 4.54373821412446e-06], [0.00010882057540584356, 1.725985566736199e-05, 0.00011263418855378404, 0.03281492739915848, 0.9669422507286072, 4.202504896966275e-06], [0.00010193466732744128, 1.6140083971549757e-05, 0.0001047439145622775, 0.03175773844122887, 0.9680155515670776, 3.919471510016592e-06], [0.00010257375106448308, 1.6430656614829786e-05, 0.00010827141522895545, 0.033712029457092285, 0.9660564064979553, 4.291730874683708e-06], [0.00011199100845260546, 1.837491618061904e-05, 0.00011858901416417211, 0.03476506099104881, 0.9649811387062073, 4.786411864188267e-06]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00dk17ZB6DoO",
        "outputId": "f05203f4-8839-4bda-f3d9-c9d8b8b79d89"
      },
      "source": [
        "print(type(testy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGMrU3XM5VQE",
        "outputId": "0c88166e-9101-4b1d-90ab-657c71cf9c0b"
      },
      "source": [
        "sum_tot = 0\n",
        "for i in range(len(output_list)):\n",
        "  ind = np.argmax(output_list[i])\n",
        "  if testy[i][ind] == 1:\n",
        "    sum_tot += 1\n",
        "print(\"accuracy :- \", sum_tot/len(output_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy :-  0.9046487953851374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAmvkMC8OGZx",
        "outputId": "41ec35d3-b01f-4b0f-a435-c98f9677e918"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model)\n",
        "model_for_export.save('/content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/exported_model')\n",
        "# _, model_file = tempfile.mkstemp('tforiginal.h5')\n",
        "# tf.keras.models.save_model(model_for_export, model_file, include_optimizer=False)\n",
        "# print('Saved Keras model to:', model_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/exported_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CU Boulder Classes/Distributed Systems CU Boulder/exported_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBKwUqT5RAHx",
        "outputId": "071fa62b-f7b1-4165-9121-249e844d050e"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_and_pruned_tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8wl4vbd3/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp8wl4vbd3/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdv39igWjVh3"
      },
      "source": [
        "# ---- applying weight clustering and quantization from this point\n",
        "export_pruned_LSTM.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-RZ3UhNBx3X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}